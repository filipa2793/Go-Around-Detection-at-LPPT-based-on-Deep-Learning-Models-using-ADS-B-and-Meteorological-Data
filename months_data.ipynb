{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing pipeline (possible to adapt to other airports):\n",
    "\n",
    "#flight data:\n",
    "#1. read the sdr and opensky csv files\n",
    "#2. change the header names in opensky to match the sdr \n",
    "#3. unit conversions (altitude=m, speed=m/s, vertical rate=m/s)\n",
    "#4. limit the data between the lat and lon of LPPt (excludes helicopters and other smaller planes)\n",
    "#5. drop duplicates, nans and any outliers (negative altitudes or speeds)\n",
    "#6. segment the flights (landings, take offs and ground => only the landings stay and each of them have an unique landing index)\n",
    "#7. merge the sdr and opensky datasets \n",
    "\n",
    "#weather data (METAR and ECMWF): \n",
    "#1. read the METAR txt file\n",
    "#2. parse all the relevant features from METAR\n",
    "#3. calculte new weather features \n",
    "#4. match the closest METAR to each flight \n",
    "#5. read the ECMWF csv file (+ cat.csv which has additional ECMWF features)\n",
    "#6. match the closest ECMWF to each flight (the closest ECMWF, the ECMWF before and the ECMWF after are put together and depending on the variable the max or min value is chosen)\n",
    "\n",
    "#feature engineering pt1:\n",
    "#1. correct the barometric altitude \n",
    "#2. assign each flight a runway (02 or 20)\n",
    "#3. calculate the distance to the runway\n",
    " \n",
    "#go around label: \n",
    "#1. go around algorithm (1 if it is a ga and 0 if it is not)\n",
    "\n",
    "#feature engineering pt2: \n",
    "#1. cut dataset (11NM to when a ga starts or before a normal flight lands, all the flights without info before a ga are taken out)\n",
    "#2. calculate new flight features (glideslope, localizer deviation and energy)\n",
    "#3. calculate go around clustering effects (ga count hourly, ga last time, ga before)\n",
    "#4. calculate in trail relationship features (loss of separation, speed and altitude difference, lead aircraft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flight data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the sdr and opensky csv files\n",
    "\n",
    "import pandas as pd\n",
    "opensky_df = pd.read_csv('opensky_abr24_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the header names in opensky to match the sdr \n",
    "#unit conversions (altitude=m, speed=m/s, vertical rate=m/s)\n",
    "\n",
    "opensky_df['datetime'] = pd.to_datetime(opensky_df['time'], unit='s')\n",
    "opensky_df['Date'] = opensky_df['datetime'].dt.date.astype(str)\n",
    "opensky_df['Time'] = opensky_df['datetime'].dt.time.astype(str)\n",
    "opensky_df['Time_Sec'] = opensky_df['datetime'].dt.hour * 3600 + opensky_df['datetime'].dt.minute * 60 + opensky_df['datetime'].dt.second\n",
    "\n",
    "opensky_df = opensky_df.rename(columns={\n",
    "    \"icao24\": \"ICAO\",\n",
    "    \"callsign\":\"Callsign\",\n",
    "    \"lat\": \"Latitude\",\n",
    "    \"lon\": \"Longitude\",\n",
    "    \"baroaltitude\": \"Altitude\",\n",
    "    \"velocity\": \"Speed\",\n",
    "    \"vertrate\": \"Vertical Rate\",\n",
    "    \"heading\": \"Heading\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limit the data between the lat and lon of the LPPT (excludes helicopters and other smaller planes)\n",
    "\n",
    "#sdr_df = sdr_df[(sdr_df['Latitude'].between(38.6, 38.9)) & (sdr_df['Longitude'].between(-9.2, -9.0))]\n",
    "opensky_df = opensky_df[(opensky_df['Latitude'].between(38.6, 38.9)) & (opensky_df['Longitude'].between(-9.2, -9.0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates, nans and any outliers (negative altitudes or speeds)\n",
    "\n",
    "required_columns = [\"Latitude\", \"Longitude\", \"Altitude\", \"Speed\", \"Vertical Rate\", \"Heading\"]\n",
    "\n",
    "cleaned_opensky = []\n",
    "for (icao, callsign, date), group in opensky_df.groupby([\"ICAO\", \"Callsign\", \"Date\"]):\n",
    "    group_clean = group.dropna(subset=required_columns)\n",
    "    if len(group_clean) > 0:\n",
    "        cleaned_opensky.append(group_clean)\n",
    "opensky_df = pd.concat(cleaned_opensky, ignore_index=True)\n",
    "\n",
    "opensky_df = opensky_df.drop(opensky_df[(opensky_df.Altitude < 0) | (opensky_df.Altitude > 2000)].index)\n",
    "opensky_df = opensky_df.drop(opensky_df[(opensky_df.Speed < 0) | (opensky_df.Speed > 250)].index)\n",
    "\n",
    "opensky_df[\"Date\"] = pd.to_datetime(opensky_df[\"Date\"])\n",
    "opensky_df = opensky_df[opensky_df[\"Date\"].dt.month == 4]\n",
    "\n",
    "features = [\"Latitude\", \"Longitude\", \"Speed\", \"Vertical Rate\", \"Heading\", \"Altitude\"]\n",
    "n_features = len(features)  \n",
    "model_df = opensky_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segment the flights (landings, take offs and ground => only the landings stay and each of them have an unique landing index)\n",
    "\n",
    "##########################################################################################################################################################\n",
    "#how it works:\n",
    "#1. remove rows with missing callsigns and callsigns from helicopters and small flights\n",
    "\n",
    "#2. organize the data per ICAO, callsign and date and sort it per choronological order (represents all the flights an aircraft made per day)\n",
    "\n",
    "#3. for each aircraft, if the time difference between two consecutive timestamps is bigger than 1800s (30 min), the data is cut and saved to a list (represents when an aircraft stopped and started a new flight => fligth phase transitions)\n",
    "\n",
    "#4. for each flight, the flight phase is found (C = ground/cruise, L = landing and T = take-off)\n",
    "    #if duration > 600 and altitude change < 50:\n",
    "        #flight phase = C \n",
    "    #if altitude min > 3000 or altitude max < 500: \n",
    "        #flight phase = C\n",
    "    #if there are static sequences in altitude, speed or vertical rate:\n",
    "        #flight phase = C\n",
    "    #if average vertical rate < 0:\n",
    "        #flight phase = L\n",
    "    #else if average vertical rate > 0:\n",
    "        #flight phase = T\n",
    "    #else: \n",
    "        #flight phase = C\n",
    "\n",
    "#5. create dataset with only the landings (each flight has a different landing index)\n",
    "#########################################################################################################################################################\n",
    "\n",
    "#function: converts the data to numeric\n",
    "def prepare_data(df):\n",
    "    numeric_cols = [\"Latitude\", \"Longitude\", \"Altitude\", \"Speed\", \"Vertical Rate\", \"Heading\"]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "#function: segments the data in order to create a dataset with the landings\n",
    "def segment_landings(df, time_col=\"Time_Sec\", min_msgs=100, threshold=10):\n",
    "    landing_index = 0\n",
    "    all_landing_data = []\n",
    "\n",
    "    df = df[df['Callsign'].notna()].copy() \n",
    "    df['Callsign'] = df['Callsign'].astype(str).str.strip().str.upper() \n",
    "    df = df[~df['Callsign'].str.startswith(('G', 'L', 'H', 'EC', 'BB', 'BS', 'IFJ', 'BAE', 'JME', 'N', 'VJH', 'KAF', 'OCEAN', 'BLAST', 'JFA', 'ANTENA'))]\n",
    "\n",
    "    for _, data in df.groupby([\"ICAO\", \"Callsign\", \"Date\"]):\n",
    "        data = data.sort_values(by=time_col).reset_index(drop=True)\n",
    "        data['Time_Diff'] = data[time_col].diff()\n",
    "\n",
    "        phase_change = data.index[data[\"Time_Diff\"] > 1800].tolist() \n",
    "        phase_change.insert(0, 0)\n",
    "        phase_change.append(len(data))\n",
    "\n",
    "        phase_attribute = [\"Unknown\"] * len(data)\n",
    "        \n",
    "        for flight_seg in range(len(phase_change) - 1):\n",
    "            start, end = phase_change[flight_seg], phase_change[flight_seg + 1]\n",
    "            phase_seg = data.iloc[start:end].copy()\n",
    "            vertrate = phase_seg[\"Vertical Rate\"].tail(min(200, len(phase_seg)))\n",
    "            avg_vertrate = vertrate.mean()\n",
    "\n",
    "            skip_landing_flag = False\n",
    "\n",
    "            altitude_change = phase_seg[\"Altitude\"].iloc[-1] - phase_seg[\"Altitude\"].iloc[0]\n",
    "            duration = phase_seg[time_col].iloc[-1] - phase_seg[time_col].iloc[0]\n",
    "\n",
    "            if duration > 600 and abs(altitude_change) < 50:\n",
    "                phase_attribute[start:end] = [\"C\"] * (end - start) \n",
    "                skip_landing_flag = True\n",
    "                continue  \n",
    "\n",
    "            altitude_tolerance = 5  \n",
    "            speed_tolerance = 3 \n",
    "            vertrate_tolerance = 0.5 \n",
    "\n",
    "            count = 0\n",
    "            for i in range(1, len(phase_seg)): \n",
    "                if (abs(phase_seg[\"Altitude\"].iloc[i] - phase_seg[\"Altitude\"].iloc[i - 1]) <= altitude_tolerance and\n",
    "                    abs(phase_seg[\"Speed\"].iloc[i] - phase_seg[\"Speed\"].iloc[i - 1]) <= speed_tolerance and\n",
    "                    abs(phase_seg[\"Vertical Rate\"].iloc[i] - phase_seg[\"Vertical Rate\"].iloc[i - 1]) <= vertrate_tolerance):\n",
    "                    count += 1\n",
    "                    final_vertrate = phase_seg[\"Vertical Rate\"].iloc[-1]\n",
    "\n",
    "                    if count >= threshold:\n",
    "                        if final_vertrate < 0.5:\n",
    "                            count = 0\n",
    "                        else:\n",
    "                            phase_attribute[start:end] = [\"C\"] * (end - start)\n",
    "                            skip_landing_flag = True\n",
    "                            break\n",
    "                else:\n",
    "                    count = 0 \n",
    "\n",
    "            if skip_landing_flag:\n",
    "                continue\n",
    "            \n",
    "            if phase_seg[\"Altitude\"].min() > 3000:\n",
    "                continue\n",
    "\n",
    "            if phase_seg[\"Altitude\"].max() < 500:\n",
    "                continue\n",
    "\n",
    "            if avg_vertrate < 0 and len(phase_seg) >= min_msgs and not skip_landing_flag:\n",
    "                phase_seg = phase_seg.copy()\n",
    "                phase_seg[\"Phase of Flight\"] = \"L\"\n",
    "                phase_seg[\"Landing_Index\"] = landing_index\n",
    "                all_landing_data.append(phase_seg)\n",
    "                landing_index += 1\n",
    "            else:\n",
    "                phase_type = \"T\" if avg_vertrate > 0 else \"C\"\n",
    "                phase_attribute[start:end] = [phase_type] * (end - start)\n",
    "\n",
    "        data[\"Phase of Flight\"] = phase_attribute\n",
    "\n",
    "    if all_landing_data:\n",
    "        return pd.concat(all_landing_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "opensky_df = prepare_data(opensky_df)\n",
    "openskylandings_df = segment_landings(opensky_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to confirm values\n",
    "features = [\"Latitude\", \"Longitude\", \"Speed\", \"Vertical Rate\", \"Heading\", \"Altitude\"]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = openskylandings_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the sdr and opensky datasets \n",
    "\n",
    "merged_df = openskylandings_df\n",
    "merged_df = merged_df.drop_duplicates(subset=['Date', 'Time', 'Time_Sec','ICAO', 'Callsign', 'Latitude', 'Longitude', 'Speed', 'Vertical Rate', 'Altitude', 'Heading'])\n",
    "merged_df = merged_df.sort_values(by=[\"ICAO\", \"Callsign\", \"Date\", \"Time_Sec\"]).reset_index(drop=True)\n",
    "merged_df['Landing_Index'] = merged_df.groupby([\"ICAO\", \"Callsign\", \"Date\"]).ngroup() + 1 \n",
    "merged_df = merged_df.drop(columns=['Time_Diff','Phase of Flight'])\n",
    "desired_order = [\n",
    "    'Date', 'Time', 'Time_Sec',\n",
    "    'ICAO', 'Callsign',\n",
    "    'Latitude', 'Longitude',\n",
    "    'Speed', 'Vertical Rate', 'Altitude', 'Heading',\n",
    "    'Landing_Index'\n",
    "]\n",
    "merged_df = merged_df[[col for col in desired_order if col in merged_df.columns]]\n",
    "merged_df.to_csv(\"april_data.csv\", mode='a', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data\n",
    "\n",
    "flight_dataset = pd.read_csv('april_data.csv', low_memory=False)\n",
    "flight_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data: METAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the METAR txt file\n",
    "#parse all the relevant features from METAR\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def parse_metar_row(metar_str, year=2024, month=4): #change the month and the year\n",
    "    \n",
    "    global last_wind_dir\n",
    "\n",
    "    time_match = re.search(r\"\\b(\\d{2})(\\d{2})(\\d{2})Z\\b\", metar_str)\n",
    "    if not time_match:\n",
    "        print(\"Time not found in:\", metar_str)\n",
    "        return None\n",
    "    \n",
    "    day, hour, minute = map(int, time_match.groups())\n",
    "    timestamp = datetime(year, month, day, hour, minute)\n",
    "\n",
    "    temp_match = re.search(r\"(\\d{2})/(\\d{2})\", metar_str)\n",
    "    temp = int(temp_match.group(1)) if temp_match else None\n",
    "\n",
    "    pressure_match = re.search(r\"Q(\\d{4})\", metar_str)\n",
    "    pressure = int(pressure_match.group(1)) if pressure_match else None\n",
    "\n",
    "    wind_match = re.search(r\"(VRB|\\d{3})(\\d{2})G?(\\d{2})?KT\", metar_str)\n",
    "\n",
    "    if wind_match:\n",
    "        try:\n",
    "            direction_str = wind_match.group(1)\n",
    "            if direction_str == \"VRB\":\n",
    "                wind_direction = last_wind_dir \n",
    "            else:\n",
    "                wind_direction = int(direction_str)\n",
    "                last_wind_dir = wind_direction\n",
    "\n",
    "            wind_speed_kt = int(wind_match.group(2))\n",
    "            wind_speed = wind_speed_kt * 0.514444444\n",
    "            wind_gust = int(bool(wind_match.group(3)))\n",
    "        except:\n",
    "            wind_direction = None\n",
    "            wind_speed = None\n",
    "            wind_gust = 0\n",
    "    else:\n",
    "        wind_direction = None\n",
    "        wind_speed = None\n",
    "        wind_gust = 0\n",
    "    \n",
    "    thunderstorm = int(bool(re.search(r\"\\bTS\\b\", metar_str)))\n",
    "    fog = int(bool(re.search(r\"\\bFG\\b\", metar_str)))\n",
    "    rain = int(bool(re.search(r\"\\bRA\\b\", metar_str)))\n",
    "    wind_shear = int(bool(re.search(r\"\\bWS\\b\", metar_str)))\n",
    "    cumo = int(bool(re.search(r\"\\bCB\\b\", metar_str)))\n",
    "    tcu = int(bool(re.search(r\"\\bTCU\\b\", metar_str)))\n",
    "    cb = 0\n",
    "    if cumo == 1 or tcu == 1: \n",
    "        cb = 1\n",
    "\n",
    "    vis_match = re.search(r\"\\b(\\d{4})\\b\", metar_str)\n",
    "    visibility = int(vis_match.group(1)) if vis_match else None\n",
    "\n",
    "    return {\n",
    "        \"Timestamp\": timestamp,\n",
    "        \"Temperature_M\": temp,\n",
    "        \"Pressure_M\": pressure,\n",
    "        \"Wind_Speed_M\": wind_speed,\n",
    "        \"Wind_Direction_M\": wind_direction,\n",
    "        \"Visibility_M\": visibility,\n",
    "        \"G_M\": wind_gust,\n",
    "        \"TS_M\": thunderstorm,\n",
    "        \"FG_M\": fog,\n",
    "        \"RA_M\": rain,\n",
    "        \"WS_M\": wind_shear,\n",
    "        \"CB_M\": cb\n",
    "    }\n",
    "\n",
    "output_file = \"april_metars.csv\"\n",
    "with open(output_file, \"w\", newline=\"\") as out_file:\n",
    "    fieldnames = [\"Timestamp\", \"Temperature_M\", \"Pressure_M\", \"Wind_Speed_M\", \"Wind_Direction_M\", \"Visibility_M\", \"G_M\", \"TS_M\", \"FG_M\", \"RA_M\", \"WS_M\", \"CB_M\"]\n",
    "    writer = csv.DictWriter(out_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    with open(\"metar.202404\", \"r\") as file: #change the month and year\n",
    "        for line in file:\n",
    "            metar = line.strip().replace(\"METAR \", \"\")\n",
    "            if metar:\n",
    "                try:\n",
    "                    row = parse_metar_row(metar)\n",
    "                    if row:\n",
    "                        writer.writerow(row)\n",
    "                except Exception as e:\n",
    "                    print(f\"error\")\n",
    "                    print(\"Line that caused error:\", metar)\n",
    "\n",
    "metars_df = pd.read_csv(output_file, parse_dates=[\"Timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculte new weather features \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calc_wind_dir_change(wind_dir_m, wind_speed_m, threshold=2.0):\n",
    "    wind_dir = pd.to_numeric(wind_dir_m, errors='coerce')\n",
    "    wind_speed = pd.to_numeric(wind_speed_m, errors='coerce')\n",
    "\n",
    "    valid = (\n",
    "        wind_dir.notna() & wind_dir.shift(1).notna() &\n",
    "        wind_speed.notna() & wind_speed.shift(1).notna())\n",
    "\n",
    "    diff = wind_dir.diff().abs()\n",
    "    diff = np.where(diff > 180, 360 - diff, diff)\n",
    "\n",
    "    change = pd.Series(np.nan, index=wind_dir.index, dtype=float) \n",
    "    change[valid] = diff[valid]\n",
    "\n",
    "    low_speed_mask = (wind_speed < threshold) | (wind_speed.shift(1) < threshold)\n",
    "    change[valid & low_speed_mask] = np.nan\n",
    "    change.iloc[0] = np.nan\n",
    "\n",
    "    change_cat = pd.Series(np.nan, index=change.index, dtype=float)\n",
    "    change_cat[change < 30] = 0\n",
    "    change_cat[change >= 30] = 1\n",
    "    change_cat.fillna(0, inplace=True)\n",
    "\n",
    "    return change, change_cat\n",
    "\n",
    "def calc_wind_dir_sector(wind_dir_m, wind_speed_m, wind_dir_change_m, decl=23.0, threshold=2.0):\n",
    "    wd = pd.to_numeric(wind_dir_m, errors='coerce')\n",
    "    ws = pd.to_numeric(wind_speed_m, errors='coerce')\n",
    "    wdc = pd.to_numeric(wind_dir_change_m, errors='coerce')\n",
    "\n",
    "    valid = (\n",
    "        wd.notna() & wd.shift(1).notna() &\n",
    "        ws.notna() & ws.shift(1).notna() &\n",
    "        wdc.notna())\n",
    "\n",
    "    area_A = ((wd >= (90 + decl)) & (wd < (270 + decl)))\n",
    "    area_B = ((wd >= (270 + decl)) & (wd <= 360)) | (wd < (90 + decl))\n",
    "\n",
    "    prev_wd = wd.shift(1)\n",
    "    prev_area_A = ((prev_wd >= (90 + decl)) & (prev_wd < (270 + decl)))\n",
    "    prev_area_B = ((prev_wd >= (270 + decl)) & (prev_wd <= 360)) | (prev_wd < (90 + decl))\n",
    "\n",
    "    cross_area = pd.Series(np.nan, index=wd.index, dtype=float)\n",
    "    same_area = ((area_A & prev_area_A) | (area_B & prev_area_B))\n",
    "\n",
    "    shear_condition = (wdc >= 10) | ((wdc >= 7.5) & (ws >= 4))\n",
    "    cross_area[valid & shear_condition & same_area] = 0\n",
    "    cross_area[valid & shear_condition & ~same_area] = 1\n",
    "\n",
    "    low_speed_mask = (ws < threshold) | (ws.shift(1) < threshold)\n",
    "    exception_mask = (ws.shift(1) < threshold) & (ws >= 2 * threshold)\n",
    "    cross_area[valid & shear_condition & low_speed_mask & ~exception_mask] = np.nan\n",
    "\n",
    "    cross_area.iloc[0] = np.nan\n",
    "    cross_area.fillna(0, inplace=True)\n",
    "\n",
    "    return cross_area\n",
    "\n",
    "wind_dir_change, wind_dir_change_cat = calc_wind_dir_change(metars_df[\"Wind_Direction_M\"], metars_df[\"Wind_Speed_M\"])\n",
    "\n",
    "metars_df[\"Wind_Dir_Change\"] = wind_dir_change\n",
    "metars_df[\"Wind_Dir_Change_M\"] = wind_dir_change_cat\n",
    "\n",
    "metars_df[\"Wind_Dir_Sector_M\"] = calc_wind_dir_sector(metars_df[\"Wind_Direction_M\"], metars_df[\"Wind_Speed_M\"], metars_df[\"Wind_Dir_Change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the closest METAR to each flight \n",
    "\n",
    "flight_dataset[\"Timestamp\"] = pd.to_datetime(flight_dataset[\"Date\"] + \" \" + flight_dataset[\"Time\"])\n",
    "landing_times = flight_dataset.groupby(\"Landing_Index\")[\"Timestamp\"].max().reset_index() \n",
    "\n",
    "#find the closest metar\n",
    "def find_closest_metar(landing_time):\n",
    "    time_metar = (metars_df[\"Timestamp\"] - landing_time).abs()\n",
    "    closest_idx = time_metar.idxmin()\n",
    "    window_df = metars_df.loc[closest_idx].copy()\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for col in [\"Temperature_M\", \"Pressure_M\", \"Wind_Speed_M\", \"Wind_Direction_M\", \"Visibility_M\", \"G_M\", \"TS_M\", \"FG_M\", \"RA_M\", \"WS_M\", \"CB_M\", 'Wind_Dir_Change', 'Wind_Dir_Change_M', 'Wind_Dir_Sector_M']:\n",
    "        result[col] = window_df[col]\n",
    "\n",
    "    result[\"Timestamp\"] = landing_time\n",
    "    return pd.Series(result)\n",
    "\n",
    "closest_metars = landing_times[\"Timestamp\"].apply(find_closest_metar)\n",
    "closest_metars = pd.concat([landing_times[\"Landing_Index\"].reset_index(drop=True), closest_metars.reset_index(drop=True)], axis=1)\n",
    "\n",
    "flight_metar_dataset = flight_dataset.merge(closest_metars, on=\"Landing_Index\", how=\"left\")\n",
    "flight_metar_dataset = flight_metar_dataset.drop(columns=['Timestamp_x','Timestamp_y'])\n",
    "flight_metar_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather data: ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the ECMWF csv file (+ cat.csv which has additional ECMWF features) \n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "input_file = \"ecmwf_mar_mai_2024.csv\"\n",
    "output_file = \"ecmwf.csv\"\n",
    "\n",
    "final_columns = [\n",
    "    \"Timestamp\", \"Visibility_E\", \"Wind_CompU_E\", \"Wind_CompV_E\", \"Wind_Gust_E\",\n",
    "    \"Wind_Shear_E\", \"CBHA_E\", \"Wind_Direction_E\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    for idx, line in enumerate(file):\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 14:\n",
    "            print(f\"[Line {idx}] Skipping malformed line with {len(parts)} columns: {line}\")\n",
    "            continue\n",
    "        try:\n",
    "            timestamp_str = parts[0]\n",
    "            timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[Line {idx}] Invalid date format: {timestamp_str}\")\n",
    "            continue\n",
    "        try:\n",
    "            visibility = float(parts[3]) \n",
    "            if visibility < 0:\n",
    "                visibility = None\n",
    "            wind_compu = float(parts[5])\n",
    "            wind_compv = float(parts[6])\n",
    "            wind_gust = float(parts[7])\n",
    "            wind_10m = float(parts[4])\n",
    "            wind_925 = float(parts[9])\n",
    "            cbha = float(parts[11])\n",
    "            wind_shear = wind_925 - wind_10m\n",
    "            wind_dir_10m = float(parts[13])\n",
    "\n",
    "            row = [\n",
    "                timestamp,\n",
    "                visibility,\n",
    "                wind_compu,\n",
    "                wind_compv,\n",
    "                wind_gust,\n",
    "                wind_shear,\n",
    "                cbha,\n",
    "                wind_dir_10m\n",
    "            ]\n",
    "\n",
    "            data.append(row)\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"[Line {idx}] Failed to convert values to float: {parts[1:]}\")\n",
    "            continue\n",
    "\n",
    "ecmwf_df = pd.DataFrame(data, columns=final_columns)\n",
    "ecmwf_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the closest ECMWF to each flight (the closest ECMWF, the ECMWF before and the ECMWF after are put together and depending on the variable the max or min value is chosen)\n",
    "\n",
    "flight_metar_dataset[\"Timestamp\"] = pd.to_datetime(flight_metar_dataset[\"Date\"] + \" \" + flight_metar_dataset[\"Time\"])\n",
    "landing_times = flight_metar_dataset.groupby(\"Landing_Index\")[\"Timestamp\"].max().reset_index()\n",
    "\n",
    "def find_closest_ecmwf(landing_time):\n",
    "    time_ecmwf = (ecmwf_df[\"Timestamp\"] - landing_time).abs()\n",
    "    closest_idx = time_ecmwf.idxmin()\n",
    "    \n",
    "    idxs = [i for i in [closest_idx - 1, closest_idx, closest_idx + 1] if i in ecmwf_df.index] \n",
    "    window_df = ecmwf_df.loc[idxs].copy()\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for col in [\"Wind_CompU_E\", \"Wind_CompV_E\", \"Wind_Gust_E\", \"Wind_Shear_E\", \"CBHA_E\", \"Wind_Direction_E\"]:\n",
    "        result[col] = window_df[col].max()\n",
    "\n",
    "    for col in [\"Visibility_E\"]:\n",
    "        result[col] = window_df[col].min()\n",
    "\n",
    "    result[\"Timestamp\"] = landing_time\n",
    "    return pd.Series(result)\n",
    "\n",
    "closest_ecmwf = landing_times[\"Timestamp\"].apply(find_closest_ecmwf)\n",
    "closest_ecmwf = pd.concat([landing_times[\"Landing_Index\"].reset_index(drop=True), closest_ecmwf.reset_index(drop=True)], axis=1)\n",
    "\n",
    "full_dataset = flight_metar_dataset.merge(closest_ecmwf, on=\"Landing_Index\", how=\"left\")\n",
    "full_dataset = full_dataset.drop(columns=['Timestamp_x','Timestamp_y']) #decidir se retiro mais ou nao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the ECMWF csv file (+ cat.csv which has additional ECMWF features)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "input_file = \"cat_timeseries.csv\"\n",
    "output_file = \"cat.csv\"\n",
    "\n",
    "final_columns = [\"Timestamp\", \"C_1000_E\", \"C_500_E\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(input_file, \"r\") as file:\n",
    "    for idx, line in enumerate(file):\n",
    "        parts = line.strip().split(\",\")\n",
    "        if len(parts) != 3:\n",
    "            print(f\"[Line {idx}] Skipping malformed line with {len(parts)} columns: {line}\")\n",
    "            continue\n",
    "        try:\n",
    "            timestamp_str = parts[0]\n",
    "            timestamp = datetime.strptime(timestamp_str, \"%Y%m%d%H\")\n",
    "        except ValueError as e:\n",
    "            print(f\"[Line {idx}] Invalid date format: {timestamp_str}\")\n",
    "            continue\n",
    "        try:\n",
    "            c1000 = float(parts[1]) \n",
    "            c500 = float(parts[2])\n",
    "\n",
    "            row = [\n",
    "                timestamp,\n",
    "                c1000,\n",
    "                c500]\n",
    "            data.append(row)\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"[Line {idx}] Failed to convert values to float: {parts[1:]}\")\n",
    "            continue\n",
    "\n",
    "cat_df = pd.DataFrame(data, columns=final_columns)\n",
    "cat_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match the closest ECMWF to each flight \n",
    "\n",
    "full_dataset[\"Timestamp\"] = pd.to_datetime(full_dataset[\"Date\"] + \" \" + full_dataset[\"Time\"])\n",
    "landing_times = full_dataset.groupby(\"Landing_Index\")[\"Timestamp\"].max().reset_index()\n",
    "\n",
    "def find_closest(landing_time):\n",
    "    time = (cat_df[\"Timestamp\"] - landing_time).abs()\n",
    "    closest_idx = time.idxmin()\n",
    "    \n",
    "    idxs = [i for i in [closest_idx - 1, closest_idx, closest_idx + 1] if i in cat_df.index] #vou buscar os indexes antes e depois\n",
    "    window_df = cat_df.loc[idxs].copy()\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for col in [\"C_1000_E\", \"C_500_E\"]:\n",
    "        result[col] = window_df[col].max()\n",
    "\n",
    "    result[\"Timestamp\"] = landing_time\n",
    "    return pd.Series(result)\n",
    "\n",
    "closest = landing_times[\"Timestamp\"].apply(find_closest)\n",
    "closest = pd.concat([landing_times[\"Landing_Index\"].reset_index(drop=True), closest.reset_index(drop=True)], axis=1)\n",
    "\n",
    "all_dataset = full_dataset.merge(closest, on=\"Landing_Index\", how=\"left\")\n",
    "all_dataset = all_dataset.drop(columns=['Timestamp_x','Timestamp_y']) \n",
    "all_dataset.replace(-999, np.nan, inplace=True)\n",
    "all_dataset.to_csv(\"april.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to confirm the values\n",
    "\n",
    "features = [\"Wind_Speed_M\", \"Wind_Direction_M\", \"Visibility_M\", \"G_M\", \"TS_M\", \"FG_M\", \"RA_M\", \"WS_M\", \"Wind_Dir_Change\", \"Wind_Dir_Change_M\", \"Wind_Dir_Sector_M\",\n",
    "            \"Wind_CompU_E\", \"Wind_CompV_E\", \"Wind_Gust_E\", \"Wind_Shear_E\", \"CBHA_E\", \"Wind_Direction_E\", \"Visibility_E\", \"C_1000_E\", \"C_500_E\"]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = all_dataset\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the data\n",
    "\n",
    "dataset = pd.read_csv(\"april.csv\", dtype={\"ICAO\": str})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature engineering part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct the barometric altitude \n",
    "\n",
    "def correct_altitude(temp, pressure, altitude):\n",
    "    if pd.isna(temp) or pd.isna(pressure) or pd.isna(altitude):\n",
    "        return None\n",
    "    T_metar = temp + 273.15 #celsius to kelvin\n",
    "    P_metar = pressure #hPa\n",
    "    Alt = altitude #meters\n",
    "    T_isa = 288.15 #K\n",
    "    P_isa = 1013.25 #hPa\n",
    "\n",
    "    try:\n",
    "        T_a = (P_isa*(1-0.0065*(Alt/T_isa))**5.2561)/P_metar\n",
    "        real_altitude_ft = ((3.28084*T_metar)*(1-(T_a)**0.190255))/0.0065\n",
    "        real_altitude = real_altitude_ft*0.3048\n",
    "        return real_altitude\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "dataset[\"Correct Altitude\"] = dataset.apply(lambda row: correct_altitude(row[\"Temperature_M\"], row[\"Pressure_M\"], row[\"Altitude\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign each flight a runway (02 or 20)\n",
    "\n",
    "def runway(group):\n",
    "    group = group.drop(columns=[\"Landing_Index\"], errors=\"ignore\")\n",
    "    \n",
    "    if len(group) < 10:\n",
    "        return pd.Series({\"Runway\": np.nan})\n",
    "    \n",
    "    heading_start = group[\"Heading\"].iloc[0]\n",
    "    rwy = \"02\" if abs(heading_start - 22.72) < abs(heading_start - 202.73) else \"20\"\n",
    "    return pd.Series({\"Runway\": rwy})\n",
    "\n",
    "runway_df = (\n",
    "    dataset.groupby(\"Landing_Index\")\n",
    "    .apply(runway, include_groups = False)\n",
    "    .reset_index())\n",
    "dataset = dataset.merge(runway_df, on=\"Landing_Index\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the distance to the runway\n",
    "\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def calc_distance(latitude, longitude, runway):\n",
    "    if runway == '02':\n",
    "        runway_points = (38.76638889,-9.14388889)\n",
    "    else:\n",
    "        runway_points = (38.79222222,-9.13000000)\n",
    "    distance = geodesic((latitude, longitude), runway_points).meters\n",
    "    return distance\n",
    "\n",
    "dataset[\"Distance\"] = dataset.apply(lambda row: calc_distance(row[\"Latitude\"], row[\"Longitude\"], row['Runway']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### go around label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go around algorithm (1 if it is a ga and 0 if it is not)\n",
    "\n",
    "##########################################################################################################################################################\n",
    "#how it works:\n",
    "#1. organize the flights per landing index and sort it per chronological order\n",
    "\n",
    "#2. if a flight has less than 30 altitude values:\n",
    "        #ga label = 0\n",
    "\n",
    "#3. if the max vertical rate is less than 8 m/s:\n",
    "        #ga label = 0\n",
    "\n",
    "#4. calculate the difference between consecutive altitudes, the index where the altitudes difference is bigger than the altitude threshold (90 m) is saved\n",
    "\n",
    "#5. if the altitude difference >= 90 m:\n",
    "        #if unrealistic jumps = true or horizontal jumps = true:\n",
    "            #apply rdp algorithm\n",
    "            #if trajectory intersects with itself (no runway change):\n",
    "                #ga label = 1\n",
    "            #else aircraft heading change (runway change + different heading):\n",
    "                #ga label = 1\n",
    "            #else 2 or more heading changes (runway change + similar heading):\n",
    "                #ga label = 1\n",
    "            #else:\n",
    "                #ga label = 0 \n",
    "        #else:\n",
    "            #ga label = 0 or errors      \n",
    "\n",
    "#6: if gradual climb = true:\n",
    "        #ga label = 1\n",
    "   #else:\n",
    "        #ga label = 0\n",
    "\n",
    "#5. add the go around label to the existing dataset\n",
    "#########################################################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "from shapely.geometry import LineString\n",
    "from rdp import rdp\n",
    "\n",
    "#function: checks if there was any gradual climb (if there is two or more 50 m climbs)\n",
    "def gradual_climb(group, window=10, min_gain=50, min_climbs=2): \n",
    "    altitudes = group[\"Altitude\"].values\n",
    "    count = 0\n",
    "    for i in range(len(altitudes) - window):\n",
    "        gain = altitudes[i + window] - altitudes[i]\n",
    "        if gain >= min_gain:\n",
    "            count += 1\n",
    "        if count >= min_climbs:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "#function: detects if a flight performed or not a go around\n",
    "def detect_ga(df, altitude_threshold=90, turning_threshold=2):\n",
    "    results = []\n",
    "    early_discarded = 0  \n",
    "\n",
    "    for landing_index, data in df.groupby(\"Landing_Index\"):\n",
    "        data = data.sort_values(\"Time_Sec\").reset_index(drop=True)\n",
    "\n",
    "        altitudes = data[\"Altitude\"].values\n",
    "        vertrates = data[\"Vertical Rate\"].values\n",
    "        coordinates = data[[\"Latitude\", \"Longitude\"]].values\n",
    "\n",
    "        if len(altitudes) < 30:\n",
    "            results.append((landing_index, 0))\n",
    "            continue\n",
    "\n",
    "        max_vertrate = np.max(vertrates)\n",
    "        if max_vertrate < 8:\n",
    "            early_discarded += 1 \n",
    "            results.append((landing_index, 0))\n",
    "            continue\n",
    "\n",
    "        altitude_diff = np.diff(altitudes)\n",
    "        altitude_climb = np.where(altitude_diff > altitude_threshold)[0]\n",
    "\n",
    "        if len(altitude_climb) > 0:\n",
    "            climb_idx = altitude_climb[0]\n",
    "            trajectory_afterclimb = coordinates[climb_idx:]\n",
    "\n",
    "            if climb_idx + 1 < len(data):\n",
    "                altitude_now = data.loc[climb_idx, \"Altitude\"]\n",
    "                altitude_next = data.loc[climb_idx + 1, \"Altitude\"]\n",
    "                jump = abs(altitude_next - altitude_now)\n",
    "\n",
    "                lat1, lon1 = data.loc[climb_idx, [\"Latitude\", \"Longitude\"]]\n",
    "                coordinates1 = (lat1, lon1)\n",
    "                lat2, lon2 = data.loc[climb_idx + 1, [\"Latitude\", \"Longitude\"]]\n",
    "                coordinates2 = (lat2, lon2)\n",
    "                dist = haversine(coordinates1, coordinates2, unit=Unit.METERS)\n",
    "\n",
    "                if jump > 1000 or dist > 7000:\n",
    "                    print(f\"Skipping Landing_Index {landing_index} — jump {jump:.0f} m, distance {dist:.1f} m\")\n",
    "                    results.append((landing_index, 0))\n",
    "                    continue\n",
    "\n",
    "            trajectory_line = LineString(trajectory_afterclimb)\n",
    "            if trajectory_line.crosses(LineString(trajectory_afterclimb)):\n",
    "                results.append((landing_index, 1))\n",
    "                continue\n",
    "\n",
    "            if \"Track Angle\" in data.columns:\n",
    "                if climb_idx + 1 < len(data):  \n",
    "                    heading_start = data.loc[climb_idx, \"Track Angle\"]\n",
    "                    heading_end = data.loc[data.index[-1], \"Track Angle\"]\n",
    "\n",
    "                    heading_diff = abs(heading_end - heading_start)\n",
    "                    heading_diff = 360 - heading_diff if heading_diff > 180 else heading_diff\n",
    "\n",
    "                    if heading_diff > 30:\n",
    "                        results.append((landing_index, 1))\n",
    "                        continue\n",
    "\n",
    "            trajectory_simplified = rdp(trajectory_afterclimb, epsilon=0.0005)\n",
    "            if len(trajectory_simplified) - 2 > turning_threshold:\n",
    "                results.append((landing_index, 1))\n",
    "                continue\n",
    "\n",
    "        gradual = gradual_climb(data, window=10, min_gain=50, min_climbs=2)\n",
    "        if gradual == 0: \n",
    "             print(f\"Skipping Landing_Index {landing_index} — no gradual ascend\")\n",
    "        results.append((landing_index, 1 if gradual else 0))\n",
    "\n",
    "    print(f\"Total flights discarded early: {early_discarded}\")     \n",
    "    return pd.DataFrame(results, columns=[\"Landing_Index\", \"Go_Around_Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go around algorithm (1 if it is a ga and 0 if it is not)\n",
    "\n",
    "go_around_labels = detect_ga(dataset)\n",
    "df = dataset.merge(go_around_labels, on=\"Landing_Index\", how=\"left\")\n",
    "\n",
    "go_around_landings = df[df[\"Go_Around_Label\"] == 1][\"Landing_Index\"].nunique()\n",
    "total_landings = df[\"Landing_Index\"].nunique()\n",
    "\n",
    "print(f\"Detected go-arounds: {go_around_landings} out of {total_landings} landings\")\n",
    "\n",
    "go_around_df = df[df[\"Go_Around_Label\"] == 1]\n",
    "go_around_summary = go_around_df.groupby(\"Landing_Index\").first().reset_index()\n",
    "\n",
    "go_around_summary[\"Callsign\"] = go_around_summary[\"Callsign\"].fillna(\"UNKNOWN\")\n",
    "go_around_summary[\"Date\"] = go_around_summary[\"Date\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "info_cols = [\"Landing_Index\", \"ICAO\", \"Callsign\", \"Date\", \"Time\"]\n",
    "go_around_info = go_around_summary[info_cols]\n",
    "\n",
    "print(go_around_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Go_Around_Label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import contextily as ctx\n",
    "\n",
    "oknib_lon, oknib_lat = -9.17861111, 38.70222222\n",
    "lis_lon, lis_lat = -9.134167, 38.774167\n",
    "ist_lon, ist_lat = -9.137961014549424, 38.73990015557909\n",
    "\n",
    "go_around_df = df[df['Go_Around_Label'] == 1]\n",
    "unique_index = go_around_df['Landing_Index'].unique()[:15]  \n",
    "\n",
    "for callsign in unique_index:\n",
    "    flight_data = go_around_df[go_around_df['Landing_Index'] == callsign]\n",
    "\n",
    "    if flight_data.empty:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    axes[0].plot(flight_data['Time_Sec'], flight_data['Altitude'], 'b-', label=\"Altitude\")\n",
    "    axes[0].scatter(flight_data['Time_Sec'], flight_data['Altitude'], c='blue', s=5)\n",
    "    axes[0].set_xlabel('Time')\n",
    "    #axes[0].set_xlim(0, 1200)\n",
    "    axes[0].set_ylabel('Altitude (m)')\n",
    "    axes[0].set_ylim(0, )\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(flight_data['Time_Sec'], flight_data['Speed'], 'r-', label=\"Velocity\")\n",
    "    axes[1].scatter(flight_data['Time_Sec'], flight_data['Speed'], c='red', s=5)\n",
    "    axes[1].set_xlabel('Time')\n",
    "    axes[1].set_ylabel('Velocity (m/s)')\n",
    "    axes[1].set_ylim(0, 200)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.suptitle(f\"Flight Data for Go-Around: {callsign}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        geometry=[Point(lon, lat) for lon, lat in zip(flight_data['Longitude'], flight_data['Latitude'])],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    gdf.plot(ax=ax, color='blue', linewidth=1, marker='o', markersize=5, label=\"Trajectory\")\n",
    "\n",
    "    ax.scatter(ist_lon, ist_lat, color='red', s=100, edgecolor='black', label=\"IST\")\n",
    "    ax.scatter(oknib_lon, oknib_lat, color='yellow', marker='*', s=100, edgecolor='black', label=\"OKNIB\")\n",
    "    ax.scatter(lis_lon, lis_lat, color='green', marker='^', s=100, edgecolor='black', label=\"LPPT\")\n",
    "\n",
    "    ax.set_xlim(-10.0, -8.0)\n",
    "    ax.set_ylim(38.4, 39.4)\n",
    "\n",
    "    ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(f\"Trajectory for Go-Around: {callsign}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature engineering part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut dataset (11NM to when a ga starts or before a normal flight lands, all the flights without info before a ga are taken out)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#function: cuts the flight data right before a go around starts since that data is not necessary \n",
    "def go_arounds_cut(group, min_gain=50, min_points=6, tolerance=1):\n",
    "    altitudes = group[\"Altitude\"].values\n",
    "    for i in range(len(altitudes) - min_points):\n",
    "        gain = altitudes[i + min_points] - altitudes[i]\n",
    "        climb = all(altitudes[i + j + 1] >= altitudes[i + j] - tolerance \n",
    "                    for j in range(min_points - 1))\n",
    "\n",
    "        if climb and gain >= min_gain:\n",
    "            cut_index = i\n",
    "            return group.iloc[:cut_index+1]  \n",
    "    return group\n",
    "\n",
    "final_dataset = []\n",
    "df[\"Distance_NM\"] = df[\"Distance\"] / 1852.0  \n",
    "\n",
    "for landing_index, data in df.groupby(\"Landing_Index\"):\n",
    "    label = data[\"Go_Around_Label\"].iat[0]\n",
    "    data = data[data[\"Distance_NM\"] <= 11.0].copy()\n",
    "    if label == 1:\n",
    "        final_data = go_arounds_cut(data)\n",
    "        if len(final_data) < 5:\n",
    "            continue\n",
    "    else:  \n",
    "        final_data = data[data[\"Distance_NM\"] >= 0.25].copy()\n",
    "        #lppt elevation = 108m, put it a bit higher to avoid having info about the plane on the ground\n",
    "        touchdown_idx = final_data[final_data[\"Altitude\"] <= 150].index.min() \n",
    "        if pd.notna(touchdown_idx):\n",
    "            final_data = final_data.loc[:touchdown_idx]\n",
    "\n",
    "    final_data = final_data.dropna(subset=[\"Altitude\", \"Distance_NM\"])\n",
    "    if len(final_data) < 5:\n",
    "        continue\n",
    "\n",
    "    final_data = final_data.copy()\n",
    "    final_data[\"Landing_Index\"] = landing_index\n",
    "    final_data[\"Go_Around_Label\"] = label\n",
    "    final_dataset.append(final_data)\n",
    "\n",
    "full_df = pd.concat(final_dataset, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique landings:\", full_df[\"Landing_Index\"].nunique())\n",
    "go_around_count = (full_df.groupby(\"Landing_Index\")[\"Go_Around_Label\"].first().value_counts())\n",
    "fraction = (go_around_count.get(1, 0)/(full_df[\"Landing_Index\"].nunique()))*100\n",
    "\n",
    "print(\"Number of normal landings (0):\", go_around_count.get(0, 0))\n",
    "print(\"Number of go-arounds (1):\", go_around_count.get(1, 0))\n",
    "print(\"Go-around %: \", fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to confirm values\n",
    "features = [\"Latitude\", \"Longitude\", \"Speed\", \"Vertical Rate\", \"Heading\", \"Altitude\"]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = full_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import contextily as ctx\n",
    "\n",
    "oknib_lon, oknib_lat = -9.17861111, 38.70222222\n",
    "lis_lon, lis_lat = -9.134167, 38.774167\n",
    "ist_lon, ist_lat = -9.137961014549424, 38.73990015557909\n",
    "\n",
    "go_around_df = full_df[full_df['Go_Around_Label'] == 1]\n",
    "unique_index = go_around_df['Landing_Index'].unique()[:15]  \n",
    "\n",
    "for callsign in unique_index:\n",
    "    flight_data = go_around_df[go_around_df['Landing_Index'] == callsign]\n",
    "\n",
    "    if flight_data.empty:\n",
    "        continue\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "    axes[0].plot(flight_data['Time_Sec'], flight_data['Altitude'], 'b-', label=\"Altitude\")\n",
    "    axes[0].scatter(flight_data['Time_Sec'], flight_data['Altitude'], c='blue', s=5)\n",
    "    axes[0].set_xlabel('Time')\n",
    "    #axes[0].set_xlim(0, 1200)\n",
    "    axes[0].set_ylabel('Altitude (m)')\n",
    "    axes[0].set_ylim(0, )\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].plot(flight_data['Time_Sec'], flight_data['Speed'], 'r-', label=\"Velocity\")\n",
    "    axes[1].scatter(flight_data['Time_Sec'], flight_data['Speed'], c='red', s=5)\n",
    "    axes[1].set_xlabel('Time')\n",
    "    axes[1].set_ylabel('Velocity (m/s)')\n",
    "    axes[1].set_ylim(0, 200)\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.suptitle(f\"Flight Data for Go-Around: {callsign}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        geometry=[Point(lon, lat) for lon, lat in zip(flight_data['Longitude'], flight_data['Latitude'])],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "\n",
    "    gdf.plot(ax=ax, color='blue', linewidth=1, marker='o', markersize=5, label=\"Trajectory\")\n",
    "\n",
    "    ax.scatter(ist_lon, ist_lat, color='red', s=100, edgecolor='black', label=\"IST\")\n",
    "    ax.scatter(oknib_lon, oknib_lat, color='yellow', marker='*', s=100, edgecolor='black', label=\"OKNIB\")\n",
    "    ax.scatter(lis_lon, lis_lat, color='green', marker='^', s=100, edgecolor='black', label=\"LPPT\")\n",
    "\n",
    "    ax.set_xlim(-10.0, -8.0)\n",
    "    ax.set_ylim(38.4, 39.4)\n",
    "\n",
    "    ctx.add_basemap(ax, crs=gdf.crs.to_string(), source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title(f\"Trajectory for Go-Around: {callsign}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate new flight features (glideslope, localizer deviation and energy)\n",
    "\n",
    "import math \n",
    "from haversine import haversine, Unit\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "def calc_glideslope(altitude, latitude, longitude, runway):\n",
    "    plane = (latitude, longitude)\n",
    "    elevation = 108\n",
    "    if runway == '02':\n",
    "        runway_points = (38.76638889,-9.14388889)\n",
    "    else:\n",
    "        runway_points = (38.79222222,-9.13000000)\n",
    "    distance = haversine(plane, runway_points, unit=Unit.METERS)\n",
    "    if distance == 0: \n",
    "        return np.nan\n",
    "    real_alt = altitude - elevation\n",
    "    glideslope_rad = math.atan(real_alt / distance)\n",
    "    glideslope_deg = math.degrees(glideslope_rad)\n",
    "    if (glideslope_deg > 5 or glideslope_deg < 0):\n",
    "        return np.nan\n",
    "    return glideslope_deg\n",
    "\n",
    "def calc_deviation(latitude, longitude, runway):\n",
    "    if runway == '02':\n",
    "        lat_i = 38.76638889 #384559.14 \n",
    "        lon_i = -9.14388889 #0090838.05\n",
    "        lat_f = 38.79638889 #384747.32\n",
    "        lon_f = -9.12777778 #0090740.17\n",
    "    else:\n",
    "        lat_i = 38.79222222 #384732.39\n",
    "        lon_i = -9.13000000 #0090748.17\n",
    "        lat_f = 38.76555556 #384556.44\n",
    "        lon_f = -9.14416667 #0090839.49\n",
    "    \n",
    "    d_lat = lat_f - lat_i\n",
    "    d_lon = lon_f - lon_i\n",
    "\n",
    "    d_lat_aircraft = latitude - lat_i\n",
    "    d_lon_aircraft = longitude - lon_i\n",
    "\n",
    "    num = (d_lat*d_lat_aircraft + d_lon*d_lon_aircraft)\n",
    "    dem = d_lat*d_lat + d_lon*d_lon\n",
    "    if dem == 0:\n",
    "        return 0\n",
    "    \n",
    "    dev = num/dem\n",
    "    closest_lon = lon_i + dev * d_lon\n",
    "    closest_lat= lat_i + dev * d_lat\n",
    "\n",
    "    deviation = geodesic((latitude, longitude), (closest_lat, closest_lon)).meters\n",
    "    if deviation > 1000:\n",
    "        return np.nan\n",
    "    return deviation\n",
    "\n",
    "def calc_energy(altitude, velocity):\n",
    "    g = 10\n",
    "    energy = altitude + (velocity**2)/(2*g)\n",
    "    return energy\n",
    "\n",
    "full_df[\"Glideslope\"] = full_df.apply(lambda row: calc_glideslope(row[\"Correct Altitude\"],row[\"Latitude\"], row[\"Longitude\"], row['Runway']), axis=1)\n",
    "full_df[\"Deviation\"] = full_df.apply(lambda row: calc_deviation(row[\"Latitude\"], row[\"Longitude\"], row['Runway']), axis=1)\n",
    "full_df[\"Energy\"] = full_df.apply(lambda row: calc_energy(row[\"Correct Altitude\"], row[\"Speed\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to confirm the values\n",
    "\n",
    "features = [\"Glideslope\", \"Deviation\", \"Energy\", \"Distance\"]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = full_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate go around clustering effects (ga count hourly, ga last time, ga before)\n",
    "\n",
    "##########################################################################################################################################################\n",
    "#how it works:\n",
    "\n",
    "#1. organize the ga data info (date, landing index, time in seconds, distance and timestamp when it starts) and flight data info (date, landing index, icao, callsign, time, time in seconds and go around label)\n",
    "\n",
    "#2. for each row in the flight data info\n",
    "    #ga before = variable previous ga that says if the previous flight index was a ga or not\n",
    "    #if time since a ga happened = none \n",
    "        #ga last time = 1440 min \n",
    "    #else: \n",
    "        #ga last time = time diff between the time since a ga happened and the flight time\n",
    "    #ga hourly = sum of all go arounds that happened in the last hour \n",
    "    #update the flight info and the ga variables in case the next flight is a go around (it is important to be careful in order to leaking future data)\n",
    "\n",
    "#4. add go around clustering effects features to dataset\n",
    "##########################################################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = full_df.copy()\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "ga_df = df[df[\"Go_Around_Label\"] == 1].copy()\n",
    "\n",
    "ga_start = (ga_df.groupby([\"Date\", \"Landing_Index\"]).last().reset_index()[[\"Date\", \"Landing_Index\", \"Time_Sec\", \"Distance\"]]\n",
    ".rename(columns={\"Time_Sec\": \"GA_Start_Time_Sec\", \"Distance\": \"GA_Start_Distance\"}))\n",
    "\n",
    "ga_start[\"GA_Start_Timestamp\"] = pd.to_datetime(ga_start[\"Date\"].astype(str)) + pd.to_timedelta(ga_start[\"GA_Start_Time_Sec\"], unit=\"s\")\n",
    "\n",
    "ga_info = ga_start.set_index([\"Date\", \"Landing_Index\"])[\"GA_Start_Timestamp\"].to_dict()\n",
    "\n",
    "flight_info = (df.groupby([\"Date\", \"Landing_Index\"]).agg({\"ICAO\": \"max\", \"Callsign\": \"max\", \"Time\": \"min\", \"Time_Sec\": \"min\", \"Go_Around_Label\": \"max\"}).reset_index())\n",
    "flight_info[\"Timestamp\"] = pd.to_datetime(flight_info[\"Date\"].astype(str) + \" \" + flight_info[\"Time\"].astype(str))\n",
    "flight_info = flight_info.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "results = []\n",
    "previous_ga = 0\n",
    "last_ga_time = None\n",
    "ga_history = []\n",
    "\n",
    "for idx, row in flight_info.iterrows():\n",
    "    current_time = row[\"Timestamp\"]\n",
    "\n",
    "    ga_before = previous_ga\n",
    "    if last_ga_time is None:\n",
    "        ga_lasttime = 1440\n",
    "    else:\n",
    "        delta_minutes = (current_time - last_ga_time).total_seconds() / 60.0\n",
    "        ga_lasttime = delta_minutes if delta_minutes <= 1440 else 1440\n",
    "\n",
    "    past_hour = current_time - pd.Timedelta(hours=1)\n",
    "    ga_hourly = sum(1 for t in ga_history if past_hour <= t < current_time)\n",
    "\n",
    "    results.append({\n",
    "        \"Date\": row[\"Date\"],\n",
    "        \"Landing_Index\": row[\"Landing_Index\"],\n",
    "        \"GA_before\": ga_before,\n",
    "        \"GA_lasttime\": ga_lasttime,\n",
    "        \"GA_hourly\": ga_hourly\n",
    "    })\n",
    "\n",
    "    if idx + 1 < len(flight_info):\n",
    "        next_row = flight_info.iloc[idx + 1]\n",
    "        next_info = f\"{next_row['Date']} | Landing_Index: {next_row['Landing_Index']} | Time: {next_row['Time']} | GA_Label: {next_row['Go_Around_Label']}\"\n",
    "    else:\n",
    "        next_info = \"None\"\n",
    "\n",
    "    print(f\"Flight {idx}: Date: {row['Date']} | Landing_Index: {row['Landing_Index']} | Time: {row['Time']} | GA_Label: {row['Go_Around_Label']}\")\n",
    "    print(f\"GA_before: {ga_before} | GA_lasttime: {ga_lasttime:.1f} min | GA_hourly: {ga_hourly}\")\n",
    "    print(f\"Next flight -> {next_info}\\n\")\n",
    "\n",
    "    if row[\"Go_Around_Label\"] == 1:\n",
    "        ga_start_time = ga_info.get((row[\"Date\"], row[\"Landing_Index\"]), None)\n",
    "        if ga_start_time is not None and pd.notna(ga_start_time) and ga_start_time <= current_time:\n",
    "            last_ga_time = ga_start_time\n",
    "            ga_history.append(last_ga_time)\n",
    "        else:\n",
    "            if last_ga_time is None or current_time > last_ga_time:\n",
    "                last_ga_time = current_time\n",
    "                ga_history.append(last_ga_time)\n",
    "        previous_ga = 1\n",
    "    else:\n",
    "        previous_ga = 0\n",
    "\n",
    "ga_final_df = pd.DataFrame(results)\n",
    "final_df = full_df.merge(ga_final_df, on=\"Landing_Index\", how=\"left\")\n",
    "final_df = final_df.drop(columns=[\"Date_y\"], errors=\"ignore\")\n",
    "final_df = final_df.rename(columns={\"Date_x\": \"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to confirm values\n",
    "features = [\"GA_before\", \"GA_lasttime\", \"GA_hourly\"]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = final_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate in trail relationship features (los, speed and altitude difference, lead aircraft)\n",
    "\n",
    "##########################################################################################################################################################\n",
    "#how it works:\n",
    "\n",
    "#1. organize the flight data info (landing index) per timestamp and runway\n",
    "\n",
    "#2. for each runway group, create a list with pairs of consecutive flights and calculate the time difference\n",
    "    #if time_diff < 10:\n",
    "        #trailing - leading pair exists\n",
    "    #else:\n",
    "        #skip\n",
    "\n",
    "#3. for each pair\n",
    "    #find the timestamp when the trailing aircraft was exactly 5 NM from the runway (time_5nm)\n",
    "    #interpolate the latitude, longitude, altitude and speed of the trailing and leading aircraft at time_5nm\n",
    "    #calcultate the separation between the leading and trailing aircraft (St)\n",
    "    #calculate the altitude and speed difference\n",
    "    #calculate the loss of separation (max(0, Sm-St))\n",
    "\n",
    "#4. add the in trail relationships features to dataset\n",
    "##########################################################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "#function: interpolates the flight's features \n",
    "def interpolate_flight(flight_df, target_time, features=[\"Latitude\", \"Longitude\", \"Altitude\", \"Speed\"]):\n",
    "    flight_df = flight_df.sort_values(\"Timestamp\")\n",
    "    results = {}\n",
    "    for feature in features:\n",
    "        x = flight_df[\"Timestamp\"].astype(np.int64) / 1e9\n",
    "        y = flight_df[feature]\n",
    "        if len(x) < 2 or x.nunique() < 2:\n",
    "            results[feature] = np.nan\n",
    "            continue\n",
    "        f_interp = interp1d(x, y, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "        results[feature] = f_interp(target_time.timestamp())\n",
    "    return results\n",
    "\n",
    "df = final_df.copy()\n",
    "\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str))\n",
    "df = df.sort_values(by=[\"Runway\", \"Timestamp\"])\n",
    "\n",
    "flight_info = (df.groupby([\"Runway\", \"Landing_Index\"])[\"Timestamp\"].max().reset_index().sort_values(by=\"Timestamp\"))\n",
    "\n",
    "pairs = []\n",
    "for rw in flight_info[\"Runway\"].unique():\n",
    "    runway_df = flight_info[flight_info[\"Runway\"] == rw]\n",
    "    for i in range(1, len(runway_df)):\n",
    "        trail = runway_df.iloc[i - 1]\n",
    "        lead = runway_df.iloc[i]\n",
    "        time_diff = (trail[\"Timestamp\"] - lead[\"Timestamp\"]).total_seconds() / 60\n",
    "        if time_diff < 10:\n",
    "            pairs.append((lead[\"Landing_Index\"], trail[\"Landing_Index\"]))\n",
    "\n",
    "df[\"Distance_NM\"] = df[\"Distance\"] / 1852\n",
    "results = []\n",
    "\n",
    "for lead_idx, trail_idx in pairs:\n",
    "    lead_df = df[df[\"Landing_Index\"] == lead_idx].sort_values(\"Distance_NM\", ascending=False)\n",
    "    trail_df = df[df[\"Landing_Index\"] == trail_idx].sort_values(\"Distance_NM\", ascending=False)\n",
    "\n",
    "    if not (trail_df[\"Distance_NM\"].min() <= 5.0 <= trail_df[\"Distance_NM\"].max()):\n",
    "        continue  \n",
    "    \n",
    "    trail_distance = trail_df[\"Distance_NM\"]\n",
    "    trail_time = trail_df[\"Timestamp\"].astype(np.int64) / 1e9\n",
    "    f_time = interp1d(trail_distance, trail_time, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "    t_5nm = f_time(5.0)\n",
    "    if np.isnan(t_5nm):\n",
    "        continue\n",
    "    time_5nm = pd.to_datetime(t_5nm, unit=\"s\")\n",
    "\n",
    "    if time_5nm < lead_df[\"Timestamp\"].min() or time_5nm > lead_df[\"Timestamp\"].max():\n",
    "        continue\n",
    "\n",
    "    trail_info = interpolate_flight(trail_df, time_5nm, features=[\"Latitude\", \"Longitude\", \"Altitude\", \"Speed\"])\n",
    "    lead_info = interpolate_flight(lead_df,  time_5nm, features=[\"Latitude\", \"Longitude\", \"Altitude\", \"Speed\"])\n",
    "\n",
    "    if any(pd.isna([trail_info[\"Latitude\"], trail_info[\"Longitude\"], \n",
    "                    lead_info[\"Latitude\"], lead_info[\"Longitude\"]])):\n",
    "        continue\n",
    "\n",
    "    coordinates_lead = (float(lead_info[\"Latitude\"]), float(lead_info[\"Longitude\"]))\n",
    "    coordinates_trail = (float(trail_info[\"Latitude\"]), float(trail_info[\"Longitude\"]))\n",
    "    St = haversine(coordinates_lead, coordinates_trail, unit=Unit.NAUTICAL_MILES)\n",
    "\n",
    "    SpeedDiff_lt = lead_info[\"Speed\"] - trail_info[\"Speed\"]\n",
    "    SpeedDiff_tl = trail_info[\"Speed\"] - lead_info[\"Speed\"]\n",
    "    AltDiff_lt = lead_info[\"Altitude\"] - trail_info[\"Altitude\"]\n",
    "    AltDiff_tl = trail_info[\"Altitude\"] - lead_info[\"Altitude\"]\n",
    "\n",
    "    Sm = 4.0 \n",
    "    LOS = max(0, Sm - St)\n",
    "\n",
    "    results.append({\n",
    "        \"Lead_Index\": lead_idx,\n",
    "        \"Trail_Index\": trail_idx,\n",
    "        \"Lead_Alt\": lead_info[\"Altitude\"],\n",
    "        \"Trail_Alt\": trail_info[\"Altitude\"], \n",
    "        \"Lead_Speed\": lead_info[\"Speed\"],\n",
    "        \"Trail_Speed\": trail_info[\"Speed\"],\n",
    "        \"Separation\": St,\n",
    "        \"LOS\": LOS,\n",
    "        \"SpeedDiff_lt\": SpeedDiff_lt,\n",
    "        \"AltDiff_lt\": AltDiff_lt,\n",
    "        \"SpeedDiff_tl\": SpeedDiff_tl,\n",
    "        \"AltDiff_tl\": AltDiff_tl,\n",
    "        \"Time\": time_5nm,\n",
    "    })\n",
    "\n",
    "df_separation = pd.DataFrame(results)\n",
    "df_filtered = df_separation[df_separation[\"LOS\"] <= 5].copy().reset_index(drop=True)\n",
    "\n",
    "trailing_with_lead = set(df_filtered[\"Trail_Index\"])\n",
    "final_df[\"Lead_Aircraft\"] = final_df[\"Landing_Index\"].apply(lambda x: 1 if x in trailing_with_lead else 0)\n",
    "\n",
    "df_filtered_renamed = df_filtered.rename(columns={\n",
    "    \"Trail_Index\": \"Landing_Index\",\n",
    "    \"SpeedDiff_lt\": \"Speed_Diff_lt\",\n",
    "    \"AltDiff_lt\": \"Alt_Diff_lt\",\n",
    "    \"SpeedDiff_tl\": \"Speed_Diff_tl\",\n",
    "    \"AltDiff_tl\": \"Alt_Diff_tl\"\n",
    "})\n",
    "\n",
    "final_df = final_df.merge(df_filtered_renamed[[\"Landing_Index\", \"LOS\", \"Alt_Diff_lt\", \"Speed_Diff_lt\", \"Alt_Diff_tl\", \"Speed_Diff_tl\"]], on=\"Landing_Index\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot: trailing vs leading aircraft altitude and speed difference and los\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for trail_idx, df in df_separation.groupby(\"Trail_Index\"):\n",
    "\n",
    "    print(f\"{trail_idx}\")\n",
    "    St = df[\"Separation\"].iloc[0]\n",
    "    Sm = 4.0  \n",
    "    LOS = df[\"LOS\"].iloc[0]\n",
    "    lead_alt = df[\"Lead_Alt\"].iloc[0]\n",
    "    trail_alt = df[\"Trail_Alt\"].iloc[0]\n",
    "    alt_diff = df[\"AltDiff_lt\"].iloc[0]\n",
    "    lead_speed = df[\"Lead_Speed\"].iloc[0]\n",
    "    trail_speed = df[\"Trail_Speed\"].iloc[0]\n",
    "    speed_diff = df[\"SpeedDiff_lt\"].iloc[0]\n",
    "\n",
    "    #Altitude\n",
    "    plt.figure(figsize=(7,6))\n",
    "    plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "    plt.scatter(0, lead_alt, color=\"blue\", s=200, marker=\">\", label=\"Leading Aircraft\")\n",
    "    plt.scatter(St, trail_alt, color=\"red\", s=200, marker=\"*\", label=\"Trailing Aircraft\")\n",
    "\n",
    "    plt.axvline(Sm, color=\"gray\", linestyle=\"--\", label=f\"Sm = {Sm:.1f} NM\")\n",
    "    plt.annotate(\n",
    "      \"\", \n",
    "      xy=(St/2, trail_alt-10), \n",
    "      xytext=(St/2, lead_alt-10), \n",
    "      arrowprops=dict(arrowstyle=\"<->\", color=\"black\", lw=1.5))\n",
    "    plt.text(St/2+0.1, (lead_alt+trail_alt)/2, \"Δh\", va=\"center\", fontsize=12)\n",
    "\n",
    "    if LOS > 0:\n",
    "        plt.annotate(\n",
    "            \"\", \n",
    "            xy=(Sm, lead_alt), \n",
    "            xytext=(St, lead_alt), \n",
    "            arrowprops=dict(arrowstyle=\"<->\", color=\"black\", lw=1.5))\n",
    "        plt.text((Sm+St)/2, lead_alt-20, f\"LOS = {LOS:.2f} NM\", ha=\"center\", va=\"top\", fontsize=12) \n",
    "\n",
    "    plt.xlim(-0.5, 4.5)  \n",
    "    plt.ylim(0, 1000) \n",
    "    plt.xlabel(\"Separation (NM)\", fontsize=18)\n",
    "    plt.ylabel(\"Altitude (m)\", fontsize=18)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xticks(fontsize=15, rotation=0)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "        spine.set_color(\"black\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "    #Speed\n",
    "    plt.figure(figsize=(7,6))\n",
    "\n",
    "    plt.scatter(0, lead_speed, color=\"blue\", s=200, marker=\">\", label=\"Leading Aircraft\")\n",
    "    plt.scatter(St, trail_speed, color=\"red\", s=200, marker=\"*\", label=\"Trailing Aircraft\")\n",
    "\n",
    "    plt.axvline(Sm, color=\"gray\", linestyle=\"--\", label=f\"Sm = {Sm:.1f} NM\")\n",
    "    plt.annotate(\n",
    "      \"\", \n",
    "      xy=(St/2, trail_speed), \n",
    "      xytext=(St/2, lead_speed), \n",
    "      arrowprops=dict(arrowstyle=\"<->\", color=\"black\", lw=1.5))\n",
    "    plt.text(St/2+0.1, (lead_speed+trail_speed)/2, \"Δv\", va=\"center\", fontsize=12)\n",
    "\n",
    "    if LOS > 0:\n",
    "        plt.annotate(\n",
    "            \"\", \n",
    "            xy=(Sm, lead_speed), \n",
    "            xytext=(St, lead_speed), \n",
    "            arrowprops=dict(arrowstyle=\"<->\", color=\"black\", lw=1.5))\n",
    "        plt.text((Sm+St)/2, lead_speed-3, f\"LOS = {LOS:.2f} NM\", ha=\"center\", va=\"top\", fontsize=12) \n",
    "\n",
    "    plt.xlim(-0.5, 4.5)  \n",
    "    plt.ylim(0, 100) \n",
    "    plt.xlabel(\"Separation (NM)\", fontsize=18)\n",
    "    plt.ylabel(\"Speed (m/s)\", fontsize=18)\n",
    "    plt.legend(fontsize=13)\n",
    "    plt.xticks(fontsize=15, rotation=0)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "        spine.set_color(\"black\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check all the values \n",
    "\n",
    "features = [\"Latitude\", \"Longitude\", \"Speed\", \"Vertical Rate\", \"Heading\", \"Correct Altitude\", \"Glideslope\", \"Deviation\", \"Energy\", \"Wind_Speed_M\",\n",
    "            \"Wind_Direction_M\", \"Visibility_M\", \"G_M\", \"TS_M\", \"FG_M\", \"RA_M\", \"WS_M\", \"Wind_Dir_Change\", \"Wind_Dir_Change_M\", \"Wind_Dir_Sector_M\"\n",
    "            \"Wind_CompU_E\", \"Wind_CompV_E\", \"Wind_Gust_E\", \"Wind_Shear_E\", \"CBHA_E\", \"Visibility_E\", \"C_1000_E\", \"C_500_E\", \"LOS\", \"Alt_Diff_lt\", \"Speed_Diff_lt\",\n",
    "            \"Alt_Diff_tl\", \"Speed_Diff_tl\", \"GA_before\", \"GA_lasttime\", \"GA_hourly\" ]\n",
    "\n",
    "n_features = len(features)  \n",
    "model_df = final_df\n",
    "\n",
    "for feature in features:\n",
    "    if feature in model_df.columns:\n",
    "        values = model_df[feature].dropna() \n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "        min_val = values.min()\n",
    "        max_val = values.max()\n",
    "        print(f\"{feature}: mean={mean:.2f}, std={std:.2f}, min={min_val:.2f}, max={max_val:.2f}\")\n",
    "    else:\n",
    "        print(f\"{feature}: not found in model_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=[\"LOS_x\", \"Alt_Diff_lt_x\", \"Speed_Diff_lt_x\", \"Alt_Diff_tl_x\", \"Speed_Diff_tl_x\", \"LOS_y\", \"Alt_Diff_lt_y\", \"Speed_Diff_lt_y\", \"Alt_Diff_tl_y\", \"Speed_Diff_tl_y\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"april24_gas.csv\", index=False)\n",
    "final_df = pd.read_csv(\"april24_gas.csv\", dtype={\"ICAO\": str})\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
